{"name":"Topicalizer","tagline":"Automatic Web API Categorization and Annotation","body":"Topicalizer\r\n=================\r\n\r\nTopicalizer is a tool that allow you to process a bunch of SOAP API descriptors\r\nin order to group the technical information they contain, in semantic related\r\ncategories, and specifying this categorization as RDF statements stored in a Sesame\r\ntriple-store. As a first step in the process of categorization, this tool applies \r\ntext processing procedures over the service descriptors for extracting some relevant\r\ntechnical information (operations, documentation and datatypes). Once such information\r\nis available, the tool fits a probabilistic topic model, known as Online LDA, for\r\ninfering a set of relevant categories (topics--distributions over terms in a fixed \r\nvocabulary), and associate a probability distribution over such topics for each one \r\nof the service operations processed by the tool.\r\n\r\nThe Online LDA processing is based on the implementation of `ONLINE VARIATIONAL \r\nBAYES FOR LATENT DIRICHLET ALLOCATION` by Matthew D. Hoffman, which uses the online \r\nVariational Bayes (VB) algorithm presented in the paper \"Online Learning for Latent \r\nDirichlet Allocation\" by Matthew D. Hoffman, David M. Blei, and Francis Bach.\r\n\r\nThe algorithm uses stochastic optimization to maximize the variational\r\nobjective function for the Latent Dirichlet Allocation (LDA) topic model.\r\nIt only looks at a subset of the total corpus of documents (namely, text files\r\nwhose content has been extracted from Web APIs documentation archives) \r\neach iteration, and thereby is able to find a locally optimal setting of\r\nthe variational posterior over the topics more quickly than a batch\r\nVB algorithm could for large corpora.\r\n\r\n\r\n##Files/Directories provided:\r\n* `lib/`: Java Dependencies.\r\n* `onlinelda/`: Folder containing the Python scripts which uses online VB for LDA to analyze \r\n  the information that has been extracted from SOAP API descriptors.\r\n* `outcome/`: This folder holds the .txt and .csv files containing the results of\r\n   applying Online LDA (`topics.<txt/csv>` and `per-document-topics.<txt/csv>`).\r\n* `sesame_war/`: Folder containing deployable distribution of the `Sesame Framework`\r\n  Server (`openrdf-sesame.war` and `openrdf-workbench.war`). \r\n* `run.sh`: Execution script.\r\n* `sample-service-uris.txt`: File containing a list of 80 service descriptors available online\r\n  (used as a sample input for the tool).\r\n* `WebAPIDocProcessing.jar` Java App for performing parsing and text processing operations\r\n  on the service descriptors.\r\n* `README.md`: This file.\r\n\r\nYou will need to have the numpy and scipy packages installed somewhere\r\nthat Python can find them to use these scripts.\r\n\r\n\r\n##System Requirements:\r\n* `Java 1.6.x` or greater.\r\n* `MySQL 5.5.x`\r\n* `Apache Tomcat 7.x` (or any available servlet container, listening at 8080 port).\r\n\r\n##Initial Settings\r\n1. In MySQL create a Database with name `service_registry`.\r\n2. Deploy both of the Sesame Framework .war files on your servlet container.\r\n   After you have deployed the Sesame Server webapp, you should be able to access it, by\r\n   default, at path `/openrdf-sesame` (`/openrdf-sesame/home/overview.view` for\r\n   Apache Tomcat 7).\r\n3. Create a new `Native Java Store` with ID `WebAPIModel` in the Sesame Server, by \r\n   accessing http://localhost:8080/openrdf-workbench/ -> `New repository`.\r\n4. Give execution permissions on the `run.sh` script. Open a terminal and type:\r\n\r\n   ```\r\n   $chmod u+x run.sh\r\n   ```\r\n##Running\r\n* Open a terminal and type `./run.sh` followed by the path of a text file containing the\r\n  list of service descriptor URIs. You could use the `sample-service-uris.txt` provided\r\n  with the tool.\r\n\r\n  ```\r\n  $./run.sh sample-service-uris.txt\r\n  ```\r\n  \r\n* After running the whole process, you could verify that the Sesame store you have created\r\n  has been populated with RDF statements corresponding to the categorization extracted by \r\n  running the Online LDA algorithm. These RDF statements instantiate the Classes and\r\n  Properties defined in the RDF Schema model available at `onlinelda/rdf_sesame/web_api_model.rdf`.\r\n  Additionally, the categorization results are also available as .txt and .csv files \r\n  at the `outcome/` foder:\r\n  \r\n  - `per-document-topics.<txt/csv>`: distribution over topics for each one of the processed \r\n  operations.\r\n\r\n  - `topics.<txt/csv>`: distributions over terms for each one of the topics extracted.\r\n  \r\n  \r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}